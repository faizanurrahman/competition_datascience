{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis DEEP Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faizanurrahman/temp_data/blob/master/Sentiment_Analysis_DEEP_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67k19TPVZQ3C",
        "colab_type": "code",
        "outputId": "ee07f59a-c1fb-474e-a062-2bf5e0ed8e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol5AiowdZiej",
        "colab_type": "code",
        "outputId": "2d686302-33a4-4742-db4e-daf4c53cef48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#import some library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(0)\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "np.random.seed(1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9vBsyduaJRF",
        "colab_type": "code",
        "outputId": "886cd765-2b88-45b1-ee47-4230aa0af27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "# read csv file\n",
        "df = pd.read_csv('/content/gdrive/My Drive/wordtovec_dataset/Tweets/Tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQwn1HzwYaFR",
        "colab_type": "code",
        "outputId": "8049bdeb-4365-4287-817c-02c958e6e02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "df.airline_sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbp-iMMkaPEI",
        "colab_type": "code",
        "outputId": "4e0dc8d0-97c2-4947-d653-3599e1c90bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# feature extract\n",
        "df = df[['text', 'airline_sentiment']].copy()\n",
        "df.columns = ['Tweet', 'Label']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet     Label\n",
              "0                @VirginAmerica What @dhepburn said.   neutral\n",
              "1  @VirginAmerica plus you've added commercials t...  positive\n",
              "2  @VirginAmerica I didn't today... Must mean I n...   neutral\n",
              "3  @VirginAmerica it's really aggressive to blast...  negative\n",
              "4  @VirginAmerica and it's a really big bad thing...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddNVPxDsarWl",
        "colab_type": "code",
        "outputId": "43ca4754-7385-4a02-9fb7-d2c4c943235b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "def Label_encode(x):\n",
        "  if x == 'neutral':\n",
        "    x = 0\n",
        "  elif x == 'positive':\n",
        "    x = 1\n",
        "  elif x == 'negative':\n",
        "    x = 2\n",
        "  return x\n",
        "df['Tweet'] = df['Tweet'].str.replace('[^\\w\\s]','')\n",
        "df['Label'] = df['Label'].apply(lambda x: Label_encode(x))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VirginAmerica What dhepburn said</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VirginAmerica plus youve added commercials to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VirginAmerica I didnt today Must mean I need t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VirginAmerica its really aggressive to blast o...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VirginAmerica and its a really big bad thing a...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet  Label\n",
              "0                   VirginAmerica What dhepburn said      0\n",
              "1  VirginAmerica plus youve added commercials to ...      1\n",
              "2  VirginAmerica I didnt today Must mean I need t...      0\n",
              "3  VirginAmerica its really aggressive to blast o...      2\n",
              "4  VirginAmerica and its a really big bad thing a...      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU8ks4qdeq-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('hotel_rev_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVaEB5mqauns",
        "colab_type": "code",
        "outputId": "a6fe0382-3fc3-45e6-83a6-f4bc14fb023b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# splitting dataset into train and validation set.\n",
        "msk = np.random.rand(len(df)) < 0.8\n",
        "train = df[msk]\n",
        "\n",
        "test = df[~msk]\n",
        "\n",
        "print('train shape: '+str(train.shape))\n",
        "print('test shape: '+ str(test.shape))\n",
        "X_train = np.asarray(train['Tweet'])\n",
        "Y_train = np.asarray(train['Label'])\n",
        "X_test = np.asarray(test['Tweet'])\n",
        "Y_test = np.asarray(test['Label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (11716, 2)\n",
            "test shape: (2924, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNTWK-ieaiCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading glove file\n",
        "from pathlib import Path\n",
        "glove_folder = Path('/content/gdrive/My Drive/wordtovec_dataset/glove.6B')\n",
        "glove_file = glove_folder / 'glove.6B.50d.txt'\n",
        "\n",
        "with open(glove_file, 'r') as glovefile:\n",
        "  word = set()\n",
        "  word_to_vec_map = {}\n",
        "  for line in glovefile:\n",
        "    line = line.strip().split()\n",
        "    curr_word = line[0]\n",
        "    word.add(curr_word)\n",
        "    word_to_vec_map[curr_word] = [float(x) for x in line[1:]]\n",
        "  \n",
        "  i = 1\n",
        "  index_to_word = {}\n",
        "  word_to_index = {}\n",
        "  for w in sorted(word):\n",
        "    word_to_index[w] = i\n",
        "    index_to_word[i] = w\n",
        "    i = i + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHVWUwita5W8",
        "colab_type": "code",
        "outputId": "6343e491-436a-4ac5-cc72-cb61e7ad4ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# max input length to model.\n",
        "max_len = max(map(lambda x: len(x), df.Tweet.str.split()))\n",
        "print(max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uTxFlSEa-B8",
        "colab_type": "code",
        "outputId": "ece01e86-a1f8-424c-ae39-c51a81701a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# convert target to one-hot encoding\n",
        "def one_hot(Y, C):\n",
        "  Y = np.eye(C)[Y.reshape(-1)]\n",
        "  return Y\n",
        "\n",
        "# sentance to indices\n",
        "def sentance_to_index(X, word_to_index, max_len):\n",
        "  m = X.shape[0]\n",
        "  X_indices = np.zeros((m, max_len))\n",
        "  for i in range(m):\n",
        "    word = X[i].lower().split()\n",
        "    j = 0\n",
        "    for w in word:\n",
        "      X_indices[i, j] = word_to_index.get(w,0)\n",
        "      j = j + 1\n",
        "  return X_indices\n",
        "\n",
        "# checking sentance_to_index\n",
        "X = np.array(['hello i am faizanur rahman'])\n",
        "X_ind = sentance_to_index(X, word_to_index, 5)\n",
        "X_ind"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[176469., 185458.,  52944.,      0., 299298.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6wlLudubPGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "  vocab_len = len(word_to_index) + 1\n",
        "  emb_dim = len(word_to_vec_map['cucumber'])\n",
        "  emb_matrix = np.zeros((vocab_len, emb_dim))\n",
        "  for word, index in word_to_index.items():\n",
        "    emb_matrix[index, :] = word_to_vec_map[word]\n",
        "  embedding_layer = Embedding(input_dim=vocab_len, output_dim=emb_dim, trainable=False)\n",
        "  embedding_layer.build((None, ))\n",
        "  embedding_layer.set_weights([emb_matrix])\n",
        "  return embedding_layer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UiQthmabdar",
        "colab_type": "code",
        "outputId": "96bf368c-c610-4f64-b4f8-23c9a7519c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "def sentiment_model(input_shape, word_to_vec_map, word_to_index):\n",
        "  \n",
        "  sentence_indices = Input(shape=input_shape, dtype=np.int32)\n",
        "\n",
        "  embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "  embeddings = embedding_layer(sentence_indices)   \n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "  X = Dropout(rate = 0.5)(X)\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "  X = Dropout(rate = 0.5)(X)\n",
        "  X = LSTM(64, return_sequences=False)(X)\n",
        "  X = Dropout(rate = 0.5)(X)\n",
        "  X = Dense(activation='softmax', units=3)(X)\n",
        "  X = Activation('softmax')(X)\n",
        "\n",
        "  # Create Model instance which converts sentence_indices into X.\n",
        "  model = Model(inputs=sentence_indices, outputs=X)\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "#creating sentment_model instance\n",
        "model = sentiment_model((max_len,), word_to_vec_map, word_to_index)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 35)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 35, 50)            20000100  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 35, 128)           91648     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 35, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 35, 128)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 35, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 195       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 20,272,935\n",
            "Trainable params: 272,835\n",
            "Non-trainable params: 20,000,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFfvdxJNw08e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "X_train_indices = sentance_to_index(X_train, word_to_index, max_len)\n",
        "Y_train_oh = one_hot(Y_train, C = 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KioTNyoobr3D",
        "colab_type": "code",
        "outputId": "d71a2c8b-fbcf-48ee-eff0-85412a60d0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1848
        }
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "X_train_indices = sentance_to_index(X_train, word_to_index, max_len)\n",
        "Y_train_oh = one_hot(Y_train, C = 3)\n",
        "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "11716/11716 [==============================] - 109s 9ms/step - loss: 0.8700 - acc: 0.6788\n",
            "Epoch 2/50\n",
            "11716/11716 [==============================] - 104s 9ms/step - loss: 0.8738 - acc: 0.6731\n",
            "Epoch 3/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.8769 - acc: 0.6658\n",
            "Epoch 4/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8796 - acc: 0.6606\n",
            "Epoch 5/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8494 - acc: 0.6922\n",
            "Epoch 6/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8319 - acc: 0.7144\n",
            "Epoch 7/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8276 - acc: 0.7194\n",
            "Epoch 8/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8461 - acc: 0.7014\n",
            "Epoch 9/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8152 - acc: 0.7322\n",
            "Epoch 10/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8312 - acc: 0.7151\n",
            "Epoch 11/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8345 - acc: 0.7070\n",
            "Epoch 12/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8057 - acc: 0.7391\n",
            "Epoch 13/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8096 - acc: 0.7375\n",
            "Epoch 14/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.8146 - acc: 0.7295\n",
            "Epoch 15/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8176 - acc: 0.7276\n",
            "Epoch 16/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.8117 - acc: 0.7355\n",
            "Epoch 17/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.8164 - acc: 0.7318\n",
            "Epoch 18/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.8026 - acc: 0.7457\n",
            "Epoch 19/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7942 - acc: 0.7538\n",
            "Epoch 20/50\n",
            "11716/11716 [==============================] - 104s 9ms/step - loss: 0.7875 - acc: 0.7590\n",
            "Epoch 21/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.7872 - acc: 0.7608\n",
            "Epoch 22/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.7855 - acc: 0.7614\n",
            "Epoch 23/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7810 - acc: 0.7670\n",
            "Epoch 24/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.7795 - acc: 0.7674\n",
            "Epoch 25/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7737 - acc: 0.7741\n",
            "Epoch 26/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7673 - acc: 0.7786\n",
            "Epoch 27/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7686 - acc: 0.7796\n",
            "Epoch 28/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.7627 - acc: 0.7837\n",
            "Epoch 29/50\n",
            "11716/11716 [==============================] - 103s 9ms/step - loss: 0.7638 - acc: 0.7826\n",
            "Epoch 30/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7603 - acc: 0.7872\n",
            "Epoch 31/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7806 - acc: 0.7673\n",
            "Epoch 32/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7583 - acc: 0.7895\n",
            "Epoch 33/50\n",
            "11716/11716 [==============================] - 100s 9ms/step - loss: 0.7703 - acc: 0.7794\n",
            "Epoch 34/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7624 - acc: 0.7861\n",
            "Epoch 35/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7537 - acc: 0.7956\n",
            "Epoch 36/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7510 - acc: 0.7977\n",
            "Epoch 37/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7479 - acc: 0.8014\n",
            "Epoch 38/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7457 - acc: 0.8037\n",
            "Epoch 39/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7453 - acc: 0.8033\n",
            "Epoch 40/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7467 - acc: 0.8031\n",
            "Epoch 41/50\n",
            "11716/11716 [==============================] - 102s 9ms/step - loss: 0.7433 - acc: 0.8052\n",
            "Epoch 42/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7376 - acc: 0.8109\n",
            "Epoch 43/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7409 - acc: 0.8080\n",
            "Epoch 44/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7399 - acc: 0.8092\n",
            "Epoch 45/50\n",
            "11716/11716 [==============================] - 100s 9ms/step - loss: 0.7481 - acc: 0.8018\n",
            "Epoch 46/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7388 - acc: 0.8109\n",
            "Epoch 47/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7359 - acc: 0.8133\n",
            "Epoch 48/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7348 - acc: 0.8151\n",
            "Epoch 49/50\n",
            "11716/11716 [==============================] - 101s 9ms/step - loss: 0.7339 - acc: 0.8164\n",
            "Epoch 50/50\n",
            "11716/11716 [==============================] - 105s 9ms/step - loss: 0.7390 - acc: 0.8115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9169be55c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cey4mqIObyiR",
        "colab_type": "code",
        "outputId": "ec86fa02-ab28-4b4a-e7d5-4235074e25f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model.save_weights(\"Hotel_reviews_weights.h5\")\n",
        "# load weights from file (can call without model.fit)\n",
        "#model.load_weights(\"/content/gdrive/My Drive/twitter_sentiment_weights.h5\")\n",
        "X_test_indices = sentance_to_index(X_test, word_to_index, max_len = max_len)\n",
        "Y_test_oh = one_hot(Y_test, C = 3)\n",
        "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2924/2924 [==============================] - 11s 4ms/step\n",
            "\n",
            "Test accuracy =  0.7633378933783921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_19SyDZncwi_",
        "colab_type": "code",
        "outputId": "e1430537-5cbc-48d1-f41f-e475e9219a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install emoji\n",
        "import emoji\n",
        "emoji_dictionary = {\"1\": \":smile:\",    # :heart\n",
        "                    \"0\": \":thumbsup:\",\n",
        "                    \"2\": \":disappointed:\",\n",
        "                    }\n",
        "\n",
        "def label_to_emoji(label):\n",
        "    return emoji.emojize(emoji_dictionary.get(str(label), emoji_dictionary['2']), use_aliases=True)\n",
        "              "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Z8VattcyWB",
        "colab_type": "code",
        "outputId": "ecf2e44a-2149-4f42-a708-2c777eca8f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# test on custom sentence.\n",
        "x_test = np.array(['i adore you'])\n",
        "X_test_indices = sentance_to_index(x_test, word_to_index, max_len)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i adore you ðŸ˜„\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL1buwJomu2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}